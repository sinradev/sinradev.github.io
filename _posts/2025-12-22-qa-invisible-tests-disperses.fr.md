---
layout: post
title: "Le QA Invisible : Quand Les Tests Sont DispersÃ©s Entre Jira, Excel Et La MÃ©moire de QA"
subtitle: "Entre test cases Excel obsolÃ¨tes, bugs Jira dÃ©connectÃ©s et rÃ©sultats perdus, personne ne sait si la release est prÃªteâ€”Sinra centralise tout"
description: "Les Ã©quipes testent sans visibilitÃ© : test cases dans Excel, bugs dans Jira, rÃ©sultats QA dans la mÃ©moire. Impossible de savoir ce qui a Ã©tÃ© testÃ©, ce qui reste, et si la release peut partir. DÃ©couvrez comment Sinra unifie QA et dÃ©veloppement."
date: 2025-12-22 09:00:00 +0100
lang: fr
category: Quality Assurance
excerpt: "Vous Ãªtes Ã  3 jours de la release. Le CTO demande : Â« On peut livrer ? Â». Vous interrogez la QA. Elle ouvre Excel, compte manuellement, vÃ©rifie ses notes, et rÃ©pond : Â« Je pense que oui... sauf si j'ai oubliÃ© quelque chose Â». Bienvenue dans le QA invisible."
permalink: /quality-assurance/:year/:month/:day/qa-invisible-tests-disperses.html
---

## Le Vendredi Avant La Release

**Vendredi 15h00. Release prÃ©vue lundi matin.**

Le CTO entre dans le bureau QA :

> Â« Marie, on est bons pour livrer lundi ? Tous les tests sont passÃ©s ? Â»

Marie (QA Lead) ouvre son laptop :

**Ã‰tape 1 :** Ouvrir Excel
- Fichier : `Test_Cases_Release_v2.3_FINAL_v4.xlsx`
- 87 test cases listÃ©s
- Colonnes : ID, Description, PrioritÃ©, Statut (Passed/Failed/Not Run)

**Ã‰tape 2 :** Compter manuellement
- 62 tests marquÃ©s Â« Passed Â»
- 18 tests marquÃ©s Â« Not Run Â»
- 7 tests marquÃ©s Â« Failed Â»

**Ã‰tape 3 :** VÃ©rifier Jira
- 14 bugs ouverts
- 8 bugs Â« In Progress Â»
- 3 bugs Â« Resolved Â» (mais pas fermÃ©s)

**Ã‰tape 4 :** Consulter ses notes
- Post-it : Â« Tester feature SSO avec Microsoft OAuth Â»
- Email : Â« N'oublie pas de retester le bug AUTH-247 Â»
- Message Slack : Â« @marie le bug de pagination est-il fixÃ© ? Â»

**30 minutes plus tard.**

Marie rÃ©pond :

> Â« Euh... je pense qu'on est bons. Il reste 18 tests non critiques que je n'ai pas eu le temps de faire. Les 7 failed sont des bugs connus en cours de fix. Normalement Ã§a devrait aller. Â»

CTO : Â« Normalement ? Â»

Marie : Â« Oui... enfin, sauf si j'ai oubliÃ© quelque chose. Â»

**Le CTO a un choix :**
- âœ… Livrer lundi (avec 18 tests non exÃ©cutÃ©s et 7 bugs actifs)
- âŒ DÃ©caler la release (et dÃ©cevoir les clients)

**Le CTO choisit :** Livrer. Â« On verra bien. Â»

**Lundi 10h00 :** Bug critique en production. Feature SSO Microsoft OAuth ne fonctionne pas.

**Cause :** Marie avait oubliÃ© de tester (c'Ã©tait sur un post-it perdu).

---

## Le ProblÃ¨me Du QA Invisible

La majoritÃ© des Ã©quipes tech gÃ¨rent leurs tests de cette faÃ§on : **QA dispersÃ© entre outils dÃ©connectÃ©s, sans visibilitÃ© globale**.

### Les Cinq SymptÃ´mes Du QA Invisible

#### 1. Test Cases Dans Excel (DÃ©connectÃ©s Du DÃ©veloppement)

**Le ScÃ©nario :**
Votre QA maintient un fichier Excel avec tous les test cases :
- `Test_Cases_v1.xlsx`
- `Test_Cases_v2_FINAL.xlsx`
- `Test_Cases_v2.3_FINAL_v4.xlsx` (le vrai fichier... ou pas ?)

**Le ProblÃ¨me :**
- âŒ Excel n'est **pas liÃ© aux features** dÃ©veloppÃ©es
- âŒ Impossible de savoir quels tests couvrent quelle feature
- âŒ Pas de synchronisation avec le code (feature ajoutÃ©e = test oubliÃ©)
- âŒ Plusieurs versions du fichier Excel (personne ne sait laquelle est Ã  jour)

**RÃ©sultat RÃ©el :**
Une Ã©quipe dÃ©couvre 3 semaines aprÃ¨s une release qu'une feature critique n'avait **aucun test case** dÃ©finiâ€”elle Ã©tait dans une ancienne version Excel perdue.

![QA DispersÃ© Entre Outils](/assets/images/blog/2025-12-22-qa-invisible-fragmented-tools.svg "Excel, Jira, Notes : Le QA FragmentÃ©")

---

#### 2. Bugs Dans Jira (Mais Aucun Lien Avec Les Tests)

**Le ScÃ©nario :**
Les bugs sont trackÃ©s dans Jira :
- `[BUG-423] Pagination broken on user list`
- `[BUG-424] SSO Microsoft OAuth fails with 500 error`
- `[BUG-425] Export PDF crashes on large datasets`

**Le ProblÃ¨me :**
- âŒ Aucun lien entre le bug et le test case qui l'a dÃ©tectÃ©
- âŒ Impossible de savoir si le bug a Ã©tÃ© retestÃ© aprÃ¨s fix
- âŒ Pas de vue globale Â« combien de bugs bloquent la release ? Â»
- âŒ QA doit manuellement croiser Excel (tests) et Jira (bugs)

**ScÃ©nario RÃ©el :**

**Marie (QA) :** Â« Le bug AUTH-247 est fixÃ© ? Â»

**Dev :** Â« Oui, fermÃ© hier. Â»

**Marie :** Â« Ok. Â»

**2 semaines plus tard :** Bug AUTH-247 rÃ©apparaÃ®t en prod.

**Pourquoi ?** Marie n'a jamais retestÃ©. Elle pensait que Â« fermÃ© Â» = Â« validÃ© QA Â». Le dev pensait que fermer le bug = QA automatique.

---

#### 3. RÃ©sultats De Tests Perdus (Aucun Historique)

**Le ScÃ©nario :**
Marie teste manuellement une feature. Elle trouve un bug, le reporte dans Jira, puis... oublie qu'elle avait dÃ©jÃ  testÃ© cette feature.

**3 semaines plus tard :**

Dev : Â« Marie, tu as retestÃ© la feature X aprÃ¨s mon fix ? Â»

Marie : Â« Euh... je crois que oui ? Attends, je vÃ©rifie. Â»

**Marie cherche :**
- Excel : aucune trace de date/rÃ©sultat
- Jira : bug fermÃ© mais pas de commentaire QA
- Notes : rien
- MÃ©moire : Â« Je pense que je l'ai testÃ© mais je ne suis pas sÃ»re. Â»

**Marie reteste.** (Temps perdu : 30 minutes pour quelque chose qu'elle avait dÃ©jÃ  fait)

**Le ProblÃ¨me :**
- âŒ Aucun historique des exÃ©cutions de tests
- âŒ Impossible de savoir Â« qui a testÃ© quoi quand Â»
- âŒ Tests dupliquÃ©s (mÃªme test exÃ©cutÃ© 2 fois par erreur)
- âŒ Tests oubliÃ©s (Â« Je pensais que quelqu'un l'avait dÃ©jÃ  testÃ© Â»)

---

#### 4. Couverture QA Invisible

**Le ScÃ©nario :**
Vous livrez une release avec 12 features.

**Question du CTO :** Â« Quelle est notre couverture de tests pour cette release ? Â»

**Processus de rÃ©ponse :**
1. Lister les 12 features
2. Ouvrir Excel, compter combien de test cases par feature
3. Compter combien de tests Â« Passed Â» vs Â« Not Run Â»
4. Reconstituer mentalement la couverture

**Temps nÃ©cessaire :** 1-2 heures.

**FiabilitÃ© :** 60% (vous avez probablement oubliÃ© quelque chose).

**RÃ©ponse finale :** Â« Je dirais qu'on est Ã  70-80% de couverture. Â»

**Le ProblÃ¨me :**
- âŒ Aucune vue automatique de la couverture
- âŒ Impossible de savoir Â« Feature X est-elle bien testÃ©e ? Â»
- âŒ DÃ©cisions de livraison basÃ©es sur intuition, pas donnÃ©es
- âŒ Pas de mÃ©trique QA fiable

---

#### 5. QA BloquÃ© En Fin De Sprint (Le Goulot d'Ã‰tranglement)

**Le ScÃ©nario :**
**Lundi-Mercredi :** Les devs codent.

**Jeudi-Vendredi :** Â« Marie, voilÃ  8 features Ã  tester pour la release de lundi. Â»

**Marie :** Â« 8 features en 2 jours ?! Â»

**RÃ©sultat :**
- Marie teste en urgence
- 50% des tests sont survolÃ©s (pas de tests approfondis)
- 30% des tests ne sont pas exÃ©cutÃ©s (pas le temps)
- Bugs trouvÃ©s vendredi soir â†’ pas le temps de fixer avant lundi

**Le ProblÃ¨me :**
- âŒ QA est traitÃ© comme une Â« phase finale Â» au lieu d'un processus continu
- âŒ Pas de visibilitÃ© en temps rÃ©el sur ce qui est prÃªt Ã  tester
- âŒ Marie ne sait pas quand les features seront prÃªtes pour elle
- âŒ Testing devient un goulot d'Ã©tranglement

![Goulot QA En Fin De Sprint](/assets/images/blog/2025-12-22-qa-invisible-bottleneck.svg "Testing En Urgence : Le Goulot d'Ã‰tranglement")

---

## Pourquoi Le QA Devient Invisible

### Raison 1 : Les Outils De Dev Et QA Sont SÃ©parÃ©s

**Les Devs Utilisent :**
- Jira/Linear pour tracker les issues
- GitHub pour le code
- CI/CD pour les tests automatisÃ©s

**La QA Utilise :**
- Excel pour les test cases
- Jira pour reporter les bugs
- Ses notes personnelles pour le suivi

**RÃ©sultat :** Deux mondes parallÃ¨les qui ne communiquent jamais.

Les devs ne savent pas ce que QA teste. QA ne sait pas ce que les devs ont dÃ©veloppÃ©.

![Dev et QA SÃ©parÃ©s](/assets/images/blog/2025-12-22-qa-invisible-dev-qa-separated.svg "Deux Mondes ParallÃ¨les Sans Communication")

---

### Raison 2 : Les Test Cases Ne Sont Pas LiÃ©s Aux Features

**Le ProblÃ¨me :**
Dans Excel, vous avez :
- `TC-001 : Test user login with valid credentials`
- `TC-002 : Test user login with invalid credentials`
- `TC-003 : Test SSO Google OAuth`

Mais **aucune information sur** :
- Quelle feature ces tests couvrent
- Quelle release nÃ©cessite ces tests
- Quel dÃ©veloppeur a implÃ©mentÃ© la feature testÃ©e
- Si la feature a changÃ© depuis la crÃ©ation du test

**RÃ©sultat :** Les test cases flottent dans le vide, dÃ©connectÃ©s du travail rÃ©el.

---

### Raison 3 : Aucune VisibilitÃ© Temps RÃ©el

**Le ProblÃ¨me :**
Le CTO demande : Â« OÃ¹ en est le testing de la release ? Â»

**Aujourd'hui, la QA doit :**
1. Ouvrir Excel
2. Compter manuellement
3. VÃ©rifier Jira pour les bugs
4. Consulter ses notes
5. Reconstituer mentalement l'Ã©tat global

**Il n'existe aucune vue temps rÃ©el** qui montre :
- Combien de tests exÃ©cutÃ©s vs restants
- Quelles features sont validÃ©es QA
- Combien de bugs bloquent la release
- Si la release peut partir

**RÃ©sultat :** Le QA est invisible jusqu'Ã  ce que quelqu'un demande explicitement.

---

## L'Approche Sinra : QA UnifiÃ© Avec Le DÃ©veloppement

Sinra a Ã©tÃ© conÃ§u pour rendre le QA **visible, liÃ© au dÃ©veloppement, et en temps rÃ©el**.

### Le Concept : Testings LiÃ©s Aux Capabilities Et Releases

Dans Sinra, les **testings** (test cases) sont directement liÃ©s aux **capabilities** (features) et aux **releases**.

**Workflow :**
1. Une capability est crÃ©Ã©e (ex: Â« Authentification SSO Â»)
2. Les issues de dÃ©veloppement sont ajoutÃ©es sous la capability
3. Les **testings** (test cases) sont crÃ©Ã©s et liÃ©s Ã  la capability
4. La QA exÃ©cute les testings et enregistre les rÃ©sultats
5. La progression QA est **automatiquement synchronisÃ©e** avec la release

**RÃ©sultat :** Dev et QA travaillent dans le mÃªme systÃ¨me, avec visibilitÃ© partagÃ©e.

![Testings LiÃ©s Aux Capabilities](/assets/images/blog/2025-12-22-qa-invisible-unified-workflow.svg "Sinra : Dev et QA UnifiÃ©s")

---

### Anatomie D'Une Feature Avec Testings Sinra

#### Ã‰tape 1 : CrÃ©er La Capability Â« Authentification SSO Â»

**Description :**
- Permettre aux utilisateurs de se connecter via Google et Microsoft OAuth

**Issues :**
- `[AUTH-120] ImplÃ©menter Google OAuth backend`
- `[AUTH-121] ImplÃ©menter Microsoft OAuth backend`
- `[AUTH-122] CrÃ©er UI sÃ©lection fournisseur SSO`
- `[AUTH-123] Ajouter gestion tokens et refresh`

---

#### Ã‰tape 2 : CrÃ©er Les Testings Pour Cette Capability

**Testings QA :**

| ID | Test Case | PrioritÃ© | LiÃ© Ã  |
|----|-----------|----------|-------|
| TC-AUTH-01 | Login Google OAuth avec compte valide | Haute | AUTH-120 |
| TC-AUTH-02 | Login Google OAuth avec compte invalide | Haute | AUTH-120 |
| TC-AUTH-03 | Login Microsoft OAuth avec compte valide | Haute | AUTH-121 |
| TC-AUTH-04 | Login Microsoft OAuth avec compte invalide | Haute | AUTH-121 |
| TC-AUTH-05 | SÃ©lection fournisseur SSO dans UI | Moyenne | AUTH-122 |
| TC-AUTH-06 | Gestion refresh token aprÃ¨s expiration | Haute | AUTH-123 |

**BÃ©nÃ©fices :**
- âœ… Chaque test est **liÃ© Ã  l'issue de dÃ©veloppement**
- âœ… Quand l'issue AUTH-120 est complÃ©tÃ©e, Sinra **alerte QA** que TC-AUTH-01 et TC-AUTH-02 sont prÃªts Ã  tester
- âœ… Pas de test oubliÃ© (impossible de marquer la capability Â« Done Â» si tests non exÃ©cutÃ©s)

---

#### Ã‰tape 3 : ExÃ©cuter Les Tests Et Enregistrer Les RÃ©sultats

**Marie (QA) exÃ©cute les tests :**

**TC-AUTH-01 : Login Google OAuth avec compte valide**
- **RÃ©sultat :** âœ… Passed
- **Date :** 2025-12-22 10:34
- **TestÃ© par :** Marie
- **Notes :** Fonctionne correctement, redirection OK, token stockÃ©

**TC-AUTH-03 : Login Microsoft OAuth avec compte valide**
- **RÃ©sultat :** âŒ Failed
- **Date :** 2025-12-22 11:02
- **TestÃ© par :** Marie
- **Bug crÃ©Ã© :** `[BUG-456] Microsoft OAuth renvoie erreur 500`
- **Notes :** Erreur serveur lors de la validation du token Microsoft

**BÃ©nÃ©fices :**
- âœ… Historique complet prÃ©servÃ© (qui, quand, rÃ©sultat, notes)
- âœ… Bug **automatiquement liÃ©** au test case et Ã  l'issue de dÃ©veloppement
- âœ… Dev reÃ§oit notification : Â« Bug dÃ©tectÃ© sur AUTH-121 par TC-AUTH-03 Â»

---

#### Ã‰tape 4 : Dev Fixe Le Bug, QA Reteste

**Dev fixe BUG-456 :**
- Commit : `Fix Microsoft OAuth token validation`
- Marque le bug Â« Resolved Â»
- Sinra **notifie automatiquement Marie** : Â« BUG-456 rÃ©solu, retester TC-AUTH-03 Â»

**Marie reteste :**
- **TC-AUTH-03 : Login Microsoft OAuth avec compte valide**
- **RÃ©sultat :** âœ… Passed (retest)
- **Date :** 2025-12-22 15:18
- **Notes :** Fix validÃ©, fonctionne correctement maintenant

**BÃ©nÃ©fices :**
- âœ… Pas de test oubliÃ© (notification automatique)
- âœ… Historique complet (failed â†’ bug â†’ fix â†’ passed)
- âœ… Synchronisation Dev â†” QA en temps rÃ©el

![Historique Complet Des Tests](/assets/images/blog/2025-12-22-qa-invisible-test-history.svg "TraÃ§abilitÃ© Totale : Failed â†’ Bug â†’ Fix â†’ Passed")

---

### Vue Globale : Progression QA Par Release

**Release : SaaS Platform v2.5 (Livraison : 2025-12-30)**

| Capability | Tests Total | Passed | Failed | Not Run | Statut QA |
|------------|-------------|--------|--------|---------|-----------|
| Authentification SSO | 6 | 6 | 0 | 0 | âœ… ValidÃ© |
| Analytics Dashboard | 8 | 5 | 1 | 2 | âš ï¸ En cours |
| API Webhooks | 10 | 0 | 0 | 10 | ğŸš¨ Pas commencÃ© |
| Export PDF | 5 | 4 | 0 | 1 | âš ï¸ En cours |

**Progression Globale QA :** 15/29 tests passÃ©s = **52% complÃ©tÃ©**

**Alertes Automatiques :**
- ğŸš¨ **API Webhooks : 0 tests exÃ©cutÃ©s** (livraison dans 8 jours)
- âš ï¸ **Analytics Dashboard : 1 bug actif** (bloque validation QA)

**BÃ©nÃ©fices :**
- âœ… Vue temps rÃ©el de l'Ã©tat QA par release
- âœ… Identification immÃ©diate des risques
- âœ… RÃ©ponse instantanÃ©e Ã  Â« On peut livrer ? Â»

**RÃ©ponse au CTO :**
> Â« Non, on ne peut pas livrer lundi. API Webhooks n'a aucun test exÃ©cutÃ©, et Analytics a encore 1 bug actif. Je recommande de dÃ©caler de 5 jours ou de retirer API Webhooks de la release. Â»

**Temps de rÃ©ponse :** 30 secondes au lieu de 2 heures.

![Dashboard Progression QA](/assets/images/blog/2025-12-22-qa-invisible-release-dashboard.svg "VisibilitÃ© Temps RÃ©el Par Release")

---

## Les Cinq Avantages Du QA UnifiÃ© Sinra

### 1. Tests LiÃ©s Aux Features (Pas Excel DÃ©connectÃ©)

**Avant (Excel) :**
- Test cases flottent dans le vide
- Aucun lien avec le code dÃ©veloppÃ©
- Features ajoutÃ©es = tests oubliÃ©s

**AprÃ¨s (Sinra) :**
- Chaque testing liÃ© Ã  une capability
- Impossible de marquer Â« Done Â» sans tests validÃ©s
- Features nouvelles = crÃ©er testings automatiquement suggÃ©rÃ©s

---

### 2. Historique Complet Des ExÃ©cutions

**Avant (Notes/MÃ©moire) :**
- Â« Je crois que j'ai testÃ© Ã§a la semaine derniÃ¨re... Â»
- Pas de trace de qui a testÃ© quoi quand
- Tests dupliquÃ©s

**AprÃ¨s (Sinra) :**
- Historique complet : date, testeur, rÃ©sultat, notes
- Â« TC-AUTH-03 testÃ© par Marie le 22/12 Ã  11h02 : Failed, bug BUG-456 crÃ©Ã© Â»
- Recherche : Â« Qui a testÃ© Microsoft OAuth ? Â» â†’ RÃ©ponse instantanÃ©e

---

### 3. Synchronisation Dev â†” QA Automatique

**Avant (Outils SÃ©parÃ©s) :**
- Dev termine une issue â†’ QA ne sait pas que c'est prÃªt
- Bug fixÃ© â†’ QA doit deviner qu'il faut retester
- DÃ©synchronisation constante

**AprÃ¨s (Sinra) :**
- Issue complÃ©tÃ©e â†’ QA notifiÃ©e automatiquement
- Bug rÃ©solu â†’ Test case Ã  rÃ©-exÃ©cuter suggÃ©rÃ©
- Dev et QA travaillent dans le mÃªme systÃ¨me

---

### 4. VisibilitÃ© Temps RÃ©el De La Couverture QA

**Avant (Calcul Manuel) :**
- Â« On est Ã  combien de couverture ? Â» â†’ 2h de calcul
- FiabilitÃ© 60%
- DÃ©cisions basÃ©es sur intuition

**AprÃ¨s (Sinra) :**
- Vue automatique : 15/29 tests passÃ©s (52%)
- Par capability : SSO 100%, Webhooks 0%
- DÃ©cisions basÃ©es sur donnÃ©es rÃ©elles

---

### 5. Goulot QA Ã‰liminÃ© (Testing Continu)

**Avant (QA En Fin De Sprint) :**
- Dev code lundi-mercredi
- QA teste jeudi-vendredi en urgence
- Bugs trouvÃ©s trop tard

**AprÃ¨s (Sinra) :**
- QA voit en temps rÃ©el quand issues sont prÃªtes
- Testing continu (dÃ¨s qu'une issue est complÃ©tÃ©e)
- Bugs dÃ©tectÃ©s tÃ´t (temps de fixer avant release)

---

## Exemple RÃ©el : HealthTech Solutions

**HealthTech Solutions (Ã©quipe de 10 personnes, plateforme SaaS santÃ©)**

*Note : HealthTech Solutions est une entreprise rÃ©elle que nous avons anonymisÃ©e sous un nom fictif pour protÃ©ger leur confidentialitÃ©.*

### Avant Sinra : QA Invisible

**Stack d'outils :**
- Excel : Test cases (`Test_Cases_v12_FINAL.xlsx`)
- Jira : Bugs et issues de dÃ©veloppement
- Notes personnelles : RÃ©sultats de tests
- Slack : Communication Dev â†” QA

**ProblÃ¨mes RencontrÃ©s :**
- **Couverture invisible :** Impossible de savoir combien de tests manquaient
- **Tests oubliÃ©s :** 2 features livrÃ©es sans aucun test (dÃ©couvert aprÃ¨s incidents prod)
- **DÃ©synchronisation :** QA testait souvent des versions obsolÃ¨tes (dev avait dÃ©jÃ  changÃ© le code)
- **Goulot QA :** Marie (seule QA) submergÃ©e en fin de sprint
- **Historique perdu :** Â« J'ai dÃ©jÃ  testÃ© Ã§a ou pas ? Â» (aucune trace)

**Incident RÃ©vÃ©lateur :**
Release Â« Patient Portal v3.2 Â» livrÃ©e avec feature Â« Export dossier mÃ©dical PDF Â».

**1 semaine aprÃ¨s la release :** 12 clients reportent que l'export PDF Ã©choue sur dossiers >50 pages.

**Analyse :** Aucun test case n'existait pour Â« Export PDF avec gros dossiers Â». Marie avait testÃ© uniquement avec petits dossiers (5 pages).

**CoÃ»t :**
- 3 semaines de fixes urgents
- 12 clients mÃ©contents
- RÃ©putation impactÃ©e

---

### AprÃ¨s Sinra : QA UnifiÃ©

**Workflow :**
1. Chaque capability a des testings dÃ©finis dÃ¨s la conception
2. QA crÃ©e test cases directement dans Sinra (liÃ©s Ã  la capability)
3. Quand dev complÃ¨te une issue, Marie est notifiÃ©e automatiquement
4. Marie exÃ©cute tests, enregistre rÃ©sultats, crÃ©e bugs si nÃ©cessaire
5. Vue temps rÃ©el de la progression QA par release

**RÃ©sultats (AprÃ¨s 4 Mois) :**
- **Couverture visible :** Vue automatique Â« Release Ã  78% testÃ©e Â»
- **Tests oubliÃ©s :** 0 (impossible de livrer sans valider testings)
- **Synchronisation :** Dev et QA alignÃ©s en temps rÃ©el
- **Goulot QA :** Ã‰liminÃ© (testing continu tout au long du sprint)
- **Historique complet :** Â« TC-PDF-05 testÃ© 3 fois : 12/12 failed, 15/12 failed, 18/12 passed Â»

**Citation Marie (QA Lead) :**
> Â« Avant, je passais 30% de mon temps Ã  chercher ce que j'avais dÃ©jÃ  testÃ© et Ã  demander aux devs ce qui Ã©tait prÃªt. Maintenant, Sinra me dit exactement quoi tester et je peux tracer tout mon travail. Je teste 2x plus et avec zÃ©ro stress. Â»

**Citation CTO :**
> Â« Fini les vendredis soir Ã  se demander si on peut livrer lundi. J'ouvre Sinra, je vois la progression QA en temps rÃ©el, et je prends une dÃ©cision basÃ©e sur des faits. Game changer. Â»

![HealthTech Avant/AprÃ¨s Sinra](/assets/images/blog/2025-12-22-qa-invisible-before-after.svg "Impact Mesurable : QA Invisible vs QA UnifiÃ©")

---

## Excel + Jira vs. Sinra : Comparaison QA

| **Aspect** | **Excel + Jira** | **Sinra Testings** |
|------------|------------------|-------------------|
| **Test cases** | Excel dÃ©connectÃ© | LiÃ©s aux capabilities |
| **Lien avec features** | âŒ Aucun | âœ… Automatique |
| **Historique exÃ©cutions** | âŒ Aucun (notes manuelles) | âœ… Complet avec dates/testeurs |
| **Synchronisation Dev â†” QA** | âŒ Manuelle | âœ… Automatique |
| **Couverture QA visible** | âŒ Calcul manuel (2h) | âœ… Temps rÃ©el (<10s) |
| **Alertes tests manquants** | âŒ Aucune | âœ… Automatiques |
| **Testing continu** | âŒ Goulot en fin de sprint | âœ… Tout au long du sprint |
| **Bugs liÃ©s aux tests** | âŒ DÃ©connectÃ©s | âœ… LiÃ©s automatiquement |
| **VisibilitÃ© release** | âŒ Â« Je pense qu'on est bons Â» | âœ… Â« 78% testÃ©s, 2 bugs actifs Â» |

---

## Les Cinq Signes Que Votre QA Est Invisible

### Signe 1 : Votre QA Utilise Excel Pour Les Test Cases

Si vos test cases vivent dans un fichier Excel dÃ©connectÃ© du dÃ©veloppement, votre QA est invisible.

---

### Signe 2 : Vous Ne Savez Pas Combien De Tests Restent Avant La Release

Si la rÃ©ponse Ã  Â« Combien de tests restent ? Â» nÃ©cessite 1h de calcul manuel, votre couverture QA est invisible.

---

### Signe 3 : QA DÃ©couvre Les Features PrÃªtes Par Hasard

Si votre QA doit demander Â« C'est prÃªt Ã  tester ? Â» au lieu d'Ãªtre notifiÃ©e automatiquement, la synchronisation est cassÃ©e.

---

### Signe 4 : Vous Livrez Sans Savoir Si Tout Est TestÃ©

Si vous rÃ©pondez Â« Je pense que oui Â» Ã  Â« Tout est testÃ© ? Â», vous n'avez aucune visibilitÃ©.

---

### Signe 5 : Bugs RÃ©apparaissent Parce Que QA A OubliÃ© De Retester

Si des bugs Â« fixÃ©s Â» reviennent parce que QA ne savait pas qu'il fallait retester, votre historique est inexistant.

---

## Comment Utiliser Sinra Pour Le QA

### Ã‰tape 1 : CrÃ©er Testings Pour Chaque Capability

**Action :**
- Chaque capability (feature) a une section Â« Testings Â»
- CrÃ©er test cases avec prioritÃ© (Haute/Moyenne/Basse)
- Lier chaque testing aux issues de dÃ©veloppement concernÃ©es

**RÃ©sultat :** Test cases liÃ©s au travail, pas flottant dans Excel.

---

### Ã‰tape 2 : ExÃ©cuter Tests Et Enregistrer RÃ©sultats

**Action :**
- Quand une issue est complÃ©tÃ©e, notification QA
- QA exÃ©cute le testing, enregistre rÃ©sultat (Passed/Failed)
- Si Failed : crÃ©er bug directement liÃ© au test

**RÃ©sultat :** Historique complet, bugs tracÃ©s.

---

### Ã‰tape 3 : Suivre Progression QA Par Release

**Action :**
- Vue release affiche % tests exÃ©cutÃ©s
- Alertes automatiques si tests manquants
- DÃ©cision de livraison basÃ©e sur donnÃ©es rÃ©elles

**RÃ©sultat :** VisibilitÃ© temps rÃ©el, dÃ©cisions informÃ©es.

---

### Ã‰tape 4 : Testing Continu (Pas Goulot En Fin De Sprint)

**Action :**
- QA teste dÃ¨s qu'issues sont complÃ©tÃ©es
- Bugs dÃ©tectÃ©s tÃ´t (temps de fixer)
- Pas d'accumulation vendredi

**RÃ©sultat :** QA devient processus continu, pas phase finale.

---

## Points d'Action : Rendre Votre QA Visible

1. **CrÃ©ez vos premiers testings dans Sinra.** Prenez 1 capability, dÃ©finissez 5-10 test cases.
2. **Liez testings aux issues de dÃ©veloppement.** Assurez visibilitÃ© Dev â†” QA.
3. **ExÃ©cutez et enregistrez rÃ©sultats.** Construisez historique complet.
4. **Suivez progression QA en temps rÃ©el.** Utilisez vue release pour visibilitÃ©.
5. **Adoptez testing continu.** Testez dÃ¨s que prÃªt, pas en fin de sprint.

---

## Le Point ClÃ©

**Le QA invisible tue la qualitÃ©.**

Entre **test cases Excel dÃ©connectÃ©s**, **bugs Jira sans lien**, **rÃ©sultats perdus**, et **couverture inconnue**, personne ne sait si la release peut partir.

**Sinra rend le QA visible et unifiÃ© avec le dÃ©veloppement.**

Les testings sont liÃ©s aux capabilities, l'historique est complet, la synchronisation est automatique, et la progression est en temps rÃ©el.

**Le rÃ©sultat :**
- âœ… Tests liÃ©s aux features (pas Excel dÃ©connectÃ©)
- âœ… Historique complet des exÃ©cutions
- âœ… Synchronisation Dev â†” QA automatique
- âœ… VisibilitÃ© temps rÃ©el de la couverture
- âœ… Goulot QA Ã©liminÃ© (testing continu)

**Vous savez exactement ce qui est testÃ©, ce qui reste, et si vous pouvez livrer.**

**Le futur vous dira merci.**

---

## DÃ©couvrez aussi la sÃ©rie Â« ProblÃ¨mes Invisibles Â»

- **[La Documentation Morte](/documentation/2025/12/24/documentation-morte-confluence-obsolete.html)** - 127 pages Confluence obsolÃ¨tes : comment rendre la documentation vivante avec Sinra Pages
- **[Le Chaos Du Backlog](/planning/2025/12/26/chaos-backlog-personne-sait-q2.html)** - 537 issues chaotiques : comment organiser le travail par releases et cycles
- **[Les DÃ©pendances CachÃ©es](/dependencies/2025/12/28/dependances-cachees-features-bloquees.html)** - 47% des features bloquÃ©es : comment rendre les dÃ©pendances visibles
- **[Le Syndrome Du Multi-Projet](/capacity/2025/12/30/syndrome-multi-projet-rien-navance.html)** - DÃ©veloppeurs sur 4 projets : comment limiter la surcharge

---

**PrÃªt Ã  rendre votre QA visible ?** [DÃ©marrez un essai gratuit de Sinra â†’](https://app.sinra.dev/users/sign_up)

DÃ©couvrez une gestion de projet oÃ¹ les tests sont liÃ©s au dÃ©veloppement, pas perdus dans Excel.
